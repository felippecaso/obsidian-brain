# BA Teams
## Roadmap Review Dez/2021
Key takeaways:
- Fluxo de solicitações no looker_help prioriza o fluxo de atendimento BA mas não as necessidades de stakeholders. Foco de dezembro em revisar o fluxo, mapeando os principais problemas possíveis e endereçando da forma correta o ticket.
- ~90% dos usuários com acesso de explorer executam pelo menos uma query desse tipo no mês, mas temos casos de uso muito localizados (ex.: poucas queries em 1 ou 2 explores) que indicam uso desnecessário.
- Plano de ação para dashboards 25+ tiles é de automatizar a comunicação de pessoas responsáveis pelo dashboard para informar o prazo de 1 semana para exclusão. Expectativa de conclusão em dezembro.
- Não temos consistência de entendimento sobre o que é um conteúdo curado, como ele agrega valor, quem utiliza e como utiliza.

### Experiência de Clientes
- [Loom](https://www.loom.com/share/a51e7f2fc5fc402383abe090e25cc64a "https://www.loom.com/share/a51e7f2fc5fc402383abe090e25cc64a")
- [Slides](https://docs.google.com/presentation/d/1l9xxeVk6JhyKquhUjqG-ZCzxZdYkmlfF8AzxKHghaWY/edit#slide=id.p "https://docs.google.com/presentation/d/1l9xxeVk6JhyKquhUjqG-ZCzxZdYkmlfF8AzxKHghaWY/edit#slide=id.p")

Thalles, William, Brendha

Objetivo: oferecer para os Lofters atendimento humanizado no que se refere à melhor utilização de dados por meio do empoderamento dos BAs com ferramentas que os fazem ser mais produtivos e assertivos

#### Key takeaways
- Fluxo de solicitações no looker_help prioriza o fluxo de atendimento BA mas não as necessidades de stakeholders. Foco de dezembro em revisar o fluxo, mapeando os principais problemas possíveis e endereçando da forma correta o ticket.

#### Feedbacks
- Sobre a redução de 67% (quanto foi em valor absoluto?) de respostas sem contato com time de BA
	- Pode ter viés de sobrevivência? Isso significa que mais gente tem contato com BA ou que menos gente respondeu a pesquisa no geral?
	- Como cruzar com outras fontes de dados que temos (ex.: consumo no Looker, evolução de pesquisas anteriores, % de cobertura por área/subárea)?
- Sobre a investigação sobre problemas no Service Desk
	- Como avaliar o impacto de cada problema ou frente de atuação? Qual métrica queremos priorizar (# de tickets, tempo de resolução, produtividade de BAs, etc.) e como isso muda a priorização?
	- Quais exemplos de tickets/casos ou depoimentos na pesquisa de satisfação reforçam os aprendizados? Sugestão de incluir pequenos recortes na apresentação!
	- Assim como no anterior, como cruzar com outras fontes de dados que temos (ex.: consumo no Looker, evolução de pesquisas anteriores, % de cobertura por área/subárea)?
- Qual impacto esperado com o novo fluxograma de atendimento?
	- Sugestão para novo fluxo: backtest com histórico de tickets (ou amostra aleatória) para garantir que casos de uso estão contemplados
- Necessidade no looker_help: alinhar com time de Gestão e Controle de Uso para ajustar as solicitações de permissão de acesso ao Looker
- E a FAQ?
	- Temos uma experiência ruim que não é atualizada frequentemente, e não tivemos nenhuma atuação até hoje.
	- Quais quick-wins conseguimos endereçar enquanto a construção do fluxo ideal não acontece?
- Quais outros leftovers? Pilar de Comunicação deixaram de atuar?
- O [Roadmap](https://docs.google.com/spreadsheets/d/1tfTgxnbZzNKNfNaBDynel0wyhFNM-roCU6erFE7xboE/edit#gid=1709744959) ainda faz sentido?

### Transformação
   - [Loom](https://www.loom.com/share/0e9cb5fa94f6419e874edaeaa7b22fc5 "https://www.loom.com/share/0e9cb5fa94f6419e874edaeaa7b22fc5")   
   - [Slides](https://docs.google.com/presentation/d/108Xgv8I9Gku1cXb51jviFtczZp89z0oxVWdt3Isam0M/edit#slide=id.p "https://docs.google.com/presentation/d/108Xgv8I9Gku1cXb51jviFtczZp89z0oxVWdt3Isam0M/edit#slide=id.p")

Giovanna, Fred, Danillo, Pedro Aud

Objetivo:

Pilares:
1. Keep the engine running
	- Ferramenta como end goal
2. Resolver/evitar problemas (processo)
	- Melhor transformação de dados
3. Alavancar dbt para potencializar entregas
	- Ferramenta como meio

#### Key takeaways

#### Feedbacks
- Na frente de "Keep engine running", qual é o racional para o trabalho na visibilidade dos dados do dbt para analytics ser o maior ponto de impacto no curto prazo para manter o motor rodando?
	- Comentaram no próprio vídeo sobre muitas quebras, e esse é de fato o maior impacto que esse pilar parece endereçar (quais ações/iniciativas/padrões devem ser feitos para que os motores continuem funcionando)
	- Senti falta de maior aprofundamento em quais seriam os principais problemas que impediriam "o motor de funcionar", e qual nosso racional de priorização para eles. Qual métrica queremos otimizar aqui?
- A dor do contrato de dados é grande no pilar de "resolver/evitar problemas", mas não é responsabilidade de BA nem do BA Team. Além do discovery realizado, quais são as frentes de atuação do time nessa parte?
- Gostei do quick win de pílulas de conhecimento do dbt como testes. Qual é a timeline de próximos passos nessa frente?
        
### Autosserviço
   - [Vídeo](https://loft-br.zoom.us/rec/share/h0Q26c5G2Itkbm-0Rnz55NM-iNdAYkiC2D-Gy3f6mpyjUxaGVWZtRzF81fIt2d5T.iuBbNjrEauZQstrW?startTime=1638376079000 "https://loft-br.zoom.us/rec/share/h0Q26c5G2Itkbm-0Rnz55NM-iNdAYkiC2D-Gy3f6mpyjUxaGVWZtRzF81fIt2d5T.iuBbNjrEauZQstrW?startTime=1638376079000")   
   - [Slides](https://docs.google.com/presentation/d/1iYluWGNYev20KCH2aTkLWVIJY-BzHWRkNNrTnJaM3ss/edit#slide=id.gfb67f7231d_0_0 "https://docs.google.com/presentation/d/1iYluWGNYev20KCH2aTkLWVIJY-BzHWRkNNrTnJaM3ss/edit#slide=id.gfb67f7231d_0_0")

Antonio, Lais, Gean

Objetivo:

Pilares:
1. Power users
	- Quem deveria ter acesso de explorer?
		- Como metrificar o uso de Power Users?
		- Quais critérios devem ser adotados na atribuição de explorer?
		- Como potencializar o uso de cada Power User?
2. Explores
	- Como evitar que o usuário cometa erros?
		- Como não ter dúvidas que nascem do fato de termos deixado alguma coisa que realmente não bate números?
		- Como evitar redefinições de campos e conceitos?
		- Como garantir que as joins funcionam de forma ampla?

#### Key takeaways
- ~90% dos usuários com acesso de explorer executam pelo menos uma query desse tipo no mês, mas temos casos de uso muito localizados (ex.: poucas queries em 1 ou 2 explores) que indicam uso desnecessário.

#### Feedbacks
- Gráfico de cenário atual/evolução de users faz sentido? Os números não somam usuários totais
- A avaliação da utilização de ~90% dos explorers serem ativos que fizeram é muito boa (e vale muito checar o efeito da automação que temos ativa de remover acessos após 30 dias sem atividade)
- Sobre a cartilha para novos usuários: já tivemos essa iniciativa no passado, no [Guia de Analytics](https://docs.google.com/document/d/1Avs3RsjE5XFeVgGi1uuG43RPRkpRteWLPHafGJ_LjOg/edit#heading=h.unicfyvl4xxe). Na opinião de vocês, funcionou? Por quê?
	- Dica: ver no arquivo do GDocs o volume de acessos por dia/semana
- No pilar de *Como evitar que o usuário cometa erros*, importante também alinhar com time de Criação de Conteúdo, explorando boas práticas de código e reutilização de blocos no LookML
- Ações e próximos passos estão focadas em discovery/entendimento. Como endereçamos ações com base no conhecimento que já temos para gerar movimento na resolução dos problemas e oportunidades mapeados?
	- Exemplo: importante alinhar com os times de *Experiência de Clientes* e *Gestão e Controle de Uso* para entender e consertar o fluxo de solicitações de mudança de acesso no looker_help
        
### Gestão e Controle de Uso
   - [Loom](https://www.loom.com/share/18019cb9f5cf45f8b23c916ffbffe378 "https://www.loom.com/share/18019cb9f5cf45f8b23c916ffbffe378")
   - [Slides](https://docs.google.com/presentation/d/1iHwVoL6ZBV1xzFQkB0LghJv1yhxSAvawqdRDtYS3RJQ/edit?usp=sharing "https://docs.google.com/presentation/d/1iHwVoL6ZBV1xzFQkB0LghJv1yhxSAvawqdRDtYS3RJQ/edit?usp=sharing")

Vitor, Ana, Paty

Objetivo:

Pilares:
- Administração do Looker
- Definição e implementação do controle de acesso
- Alertas e monitoramento de performance
- Habilitação de ferramentas internas e controle (ex.: agendamentos)

#### Key takeaways
- Plano de ação para dashboards 25+ tiles é de automatizar a comunicação de pessoas responsáveis pelo dashboard para informar o prazo de 1 semana para exclusão. Expectativa de conclusão em dezembro.

#### Feedbacks
- Como centralizar o consumo de métricas sobre o Looker? Já temos algumas visões prontas para serem complementadas, exemplos [nessa pasta](https://loftinternal.looker.com/folders/491) e na página Admin do Looker
	- A maior importância de ter isso é descobrir métricas de saúde que nos permitem atuar de forma preventiva ao invés de precisar de planos de ação (ex.: bot) ou taskforces (ex.: dashs 25+ tiles) só quando algo acontecer
	- Isso estabiliza alguns conceitos importantes, como por exemplo a visão de 25+ tiles só precisar considerar tiles com queries, e eventualmente até considerar tiles com Merge Queries com peso x2
- Quais outras métricas de observabilidade precisamos ter? Tem muitas boas práticas de Princípios de Engenharia e Foundation que podemos aplicar aqui, inclusive acionando DataX (tanto para ajuda com Cluster Databricks quanto do próprio Looker)
- A frente de alertas e monitoramento de performance é essencial de ser endereçada no curto prazo. Caminhamos "para trás" nos processos e métodos que tínhamos de gestão de crise, como por exemplo os motoristas da semana e ⚡️ de resposta a instabilidade. Como estão priorizando essa frente mais ampla?

### Criação de Conteúdo
   - [Video](https://loft-br.zoom.us/rec/share/bHejcWGDTRqQK31XSChwxqVxs4NaToYd2GoMKLA-PF_hMlLW675lfT8wyFikyKoe.zmRdCgKTGVZ3wpHG?startTime=1638484759000 "https://loft-br.zoom.us/rec/share/bHejcWGDTRqQK31XSChwxqVxs4NaToYd2GoMKLA-PF_hMlLW675lfT8wyFikyKoe.zmRdCgKTGVZ3wpHG?startTime=1638484759000")
   - [Slides](https://docs.google.com/presentation/d/10T63dnDovLIJa86N8iAtijSHhV2ldUTHPQKJeL7_fVU/edit#slide=id.g104f4cc4b57_0_88 "https://docs.google.com/presentation/d/10T63dnDovLIJa86N8iAtijSHhV2ldUTHPQKJeL7_fVU/edit#slide=id.g104f4cc4b57_0_88")

Luiz, Akio, Josy

Objetivo: otimizar a produtividade de desenvolvimento do time de BA e garantir que o time tenha as ferramentas e conhecimento necessários para criar códigos e soluções mais resilientes de criação de conteúdos no Looker.

Pilares:
- Utilização e features do LookML
- Formas de garantir qualidade e padrão de código
- Guia para sustentação e monitoramento
- Treinamento de BAs + subir a barra


#### Key takeaways


#### Feedbacks
- Sobre Pull Requests no Looker
	- Qual é o racional por trás de ser uma iniciativa com maior impacto no pilar de Sustentação e Monitoramento e não no de Qualidade e Padrão de Código?
	- Qual métrica esperamos otimizar com os PRs (ex.: retrabalho), e quais são possíveis trade-offs que precisamos levar em consideração na decisão?
	- O que impediu que a pesquisa com o time fosse disparada? E como o resultado dela vai ser levado em consideração (em outras palavras: qual é a [matriz RACI](https://www.cio.com/article/2395825/project-management-how-to-design-a-successful-raci-project-plan.html) desse plano)?
- Quais são os próximos passos em todas as frentes? Não ficou muito claro daqui em diante o que pretendem fazer pelo próximo mês e as expectativas de impacto gerado
        
### Comunicação com Dados
    
   - [Loom](https://www.loom.com/share/0b3540c938164b23aa7796bb3e4d0efb "https://www.loom.com/share/0b3540c938164b23aa7796bb3e4d0efb")
   - [Slides](https://docs.google.com/presentation/d/1brn2aEtv7Xu-6ORRlpAVEP-GkrJHzu3enxgvZ3bMFqo/edit#slide=id.p "https://docs.google.com/presentation/d/1brn2aEtv7Xu-6ORRlpAVEP-GkrJHzu3enxgvZ3bMFqo/edit#slide=id.p")

Pedro Barchi, Kelly, JP

Objetivo: democratizar o consumo de informação por meio da comunicação com dados, deixando as principais informações do negócio acessíveis e claras

Pilares:

#### Key takeaways
- Não temos consistência de entendimento sobre o que é um conteúdo curado, como ele agrega valor, quem utiliza e como utiliza.

#### Feedbacks
- A definição de Power User é diferente daquela que o time de Autosserviço tem usado. Pode ser legal um sync/thread pra alinhar os conceitos!
- Desenhar o conteúdo em cima dos conceitos chave foi uma ótima forma de consolidar o entendimento de vocês sobre o assunto. Uma forma muito legal e importante de potencializar isso é garantir que não seja somente um conteúdo/conhecimento do time de vocês e sim que gere uma construção para a área de BA!
	- Ainda assim, foram muitas *perguntas* boas mas com poucas *hipóteses* ou *propostas*. Será que todas as respostas precisam ser construídas de forma coletiva, ou podemos começar com alguma proposta inicial (ex.: para "o que é um dashboard curado")?
- Qual foi o trabalho realizado no último mês? Ficou pouco claro o que já conseguiram mapear e construir de valor até agora, chegou muito rápido nos próximos passos!
- Sobre entrevista com Lofters: será que há necessidade de pesquisa, já que temos acesso a boa parte das informações sobre comportamento de uso do Looker das pessoas nos explores de System Activity?
	- Parece ser a melhor forma de começar, já que com base nisso podem ser traçadas hipóteses que vão gerar melhores perguntas em uma eventual pesquisa qualitativa
- Sobre ambiente curado de dashboards: já temos algo ativo e acontecendo, que a Loft interage diariamente. Como vocês avaliam a qualidade do que temos hoje? Existem quick-wins que podem ser endereçados para gerar ganhos incrementais de experiência e qualidade de entrega (ex.: nos headers de dashboards curados) enquanto o plano grande e embasado é construído?
- Ótimo o TL;DR na apresentação, principalmente com a visão de qual métrica querem impactar (consumo em dashs curados)! Mas...
	- Qual é o estado dela atualmente? Voltamos a ser capazes de mensurá-la (dado que há alguns meses tivemos problemas com uma versão do Looker que quebrou o indicador)? 
	- Qual é o conceito da métrica? Ele é conhecido por todo mundo de BA? Onde está disponível para consumo?




## Proposta de formato para 2022
- Q1 continuamos iguais 
	- Dúvida: quem entrar na Loft passa a fazer parte de algum time?
	- Objetivo de matar tudo até Q2, mas podemos abraçar alguns temas de forma horizontal conforme o time de [[Analytics Ops]] vai se desenvolvendo (é estranho alguns times existirem e outros não)
- Temos uma ordem de problemas pra atacar (post-its em um board)
	- Time de Analytics Ops abraça as que estiverem no topo
	- As de baixo ficam disponíveis como catálogo se um grupo de pessoas da equipe quiser atacar
		- Terão apoio e modus operandi pra fazer, dentro da estrutura de Analytics Ops
		- Pode dedicar 10% do tempo pra isso (significa 1 dia inteiro a cada 2 semanas, ou 1/2 dia por semana)

